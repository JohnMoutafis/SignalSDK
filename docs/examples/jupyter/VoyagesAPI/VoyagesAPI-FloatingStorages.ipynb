{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzvBnaNeSoix"
   },
   "source": [
    "# Voyages API Voyages Data Like Use Case\n",
    "\n",
    "## Run this example in [Colab](https://colab.research.google.com/github/SignalOceanSdk/SignalSDK/blob/master/docs/examples/jupyter/VoyagesAPI/VoyagesAPI-VoyagesDataLike.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify\"> \n",
    "     Floating Storages are laden vessels that remain stopped, instead of directly proceeding with the laden part of the voyage and the discharge of the cargo. This is usually performed for trading reasons. The minimum duaration for a stop to be classified as a Floating Storage is 7 days for concluded Stops and 3 days for ongoing ones. \n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: justify\"> \n",
    "    Very often arises the need of conducting an analysis of the total quantity of the quantity of oil that remains in floating storages, either globally or in a specific area/port and for a given time window. This is accommodated by the <b>VoyagesData API</b>\n",
    "</p>\n",
    "\n",
    "Both `get_voyages_by_advanced_search` and `get_voyages_flat_by_advanced_search` of the Signal SDK facilititate this need. In this example, we will be constructing a dataframe with all the floating storage events of interest, from which a time series of total stored quantitites will be derived.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rk9HODZvSoi5"
   },
   "source": [
    "## Setup\n",
    "Install the Signal Ocean SDK:\n",
    "```\n",
    "pip install signal-ocean\n",
    "```\n",
    "Set your subscription key acquired here: https://apis.signalocean.com/profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VKO79fESoi6"
   },
   "outputs": [],
   "source": [
    "pip install signal-ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9lAVgQjSoi8"
   },
   "outputs": [],
   "source": [
    "signal_ocean_api_key = '' #replace with your subscription key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JWf1w-CtSoi8"
   },
   "outputs": [],
   "source": [
    "from signal_ocean import Connection\n",
    "from signal_ocean.voyages import VoyagesAPI\n",
    "from signal_ocean.voyages import VesselClass, VesselClassFilter\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta, datetime, timezone\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FTbI4qFdSoi9"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YltH0cw6Soi-"
   },
   "outputs": [],
   "source": [
    "connection = Connection(signal_ocean_api_key)\n",
    "api = VoyagesAPI(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pB5ASYxSoi-"
   },
   "source": [
    "### Get voyages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8X5V-jF0Soi_"
   },
   "source": [
    "For this tutorial we will retrieve the voyages of VLCC vessels that have started between July 2019-2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get vessel class id for vlcc\n",
    "vc = api.get_vessel_classes(VesselClassFilter('vlcc'))[0]\n",
    "vlcc_id = vc.vessel_class_id\n",
    "vlcc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dlk9A5AFSoi_"
   },
   "outputs": [],
   "source": [
    "start_date_to = date(2020,7,31)\n",
    "start_date_from = start_date_to - relativedelta(months=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "voyages = api.get_voyages_by_advanced_search(\n",
    "    vessel_class_id = vlcc_id,\n",
    "    start_date_from = start_date_from,\n",
    "    start_date_to = start_date_to\n",
    ")\n",
    "voyages = pd.DataFrame(v.__dict__ for v in voyages)\n",
    "events = pd.DataFrame(e.__dict__ for voyage_events in voyages['events'].dropna() for e in voyage_events)\n",
    "event_details = pd.DataFrame(d.__dict__ for event_detail in events['event_details'].dropna() for d in event_detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting floating storage events\n",
    "floating_storage_events_data = []\n",
    "\n",
    "for iVoyage, r in voyages.iterrows():\n",
    "    imo = r['imo']\n",
    "    voyage_number = r['voyage_number']\n",
    "    vessel_class = r['vessel_class']\n",
    "    cargo_group = r['cargo_group']\n",
    "    cargo_type = r['cargo_type']\n",
    "    quantity = r['quantity']\n",
    "\n",
    "    events = r['events']\n",
    "    \n",
    "    for event in events:\n",
    "        if not event.event_details:\n",
    "            continue\n",
    "        port_name = event.port_name\n",
    "        country = event.country\n",
    "        \n",
    "        for event_detail in event.event_details:\n",
    "            if not event_detail.floating_storage_start_date:\n",
    "                continue\n",
    "            floating_storage_start_date = event_detail.floating_storage_start_date\n",
    "            floating_storage_duration = event_detail.floating_storage_duration\n",
    "            \n",
    "            floating_storage_events_data.append([\n",
    "                imo, voyage_number, vessel_class,cargo_group,cargo_type, quantity,\n",
    "                port_name, country, floating_storage_start_date, \n",
    "                floating_storage_duration\n",
    "            ])\n",
    "\n",
    "floating_storage_events_df = pd.DataFrame(floating_storage_events_data, \n",
    "                                           columns=['imo', 'voyage_number', 'vessel_class','cargo_group', 'cargo_type',\n",
    "                                                    'quantity', 'port_name', 'country','floating_storage_start_date', \n",
    "                                                    'floating_storage_duration'\n",
    "                                                   ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the user can set a higher threshold for a Stop to be considered as a Floating Storage. In this example, we use 20 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the threshold in days to filter floating_storage_duration\n",
    "threshold = 20\n",
    "floating_event_details = event_details.loc[event_details.floating_storage_duration >= threshold,\n",
    "                                           ['event_id','floating_storage_start_date', 'floating_storage_duration']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floating_storage_events_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only the date part of floating_storage_start_date, since the floating_storage_duration is given in days\n",
    "floating_storage_events_df['floating_storage_start_date'] = floating_storage_events_df.floating_storage_start_date.apply(lambda x: x.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = ['Fueloil', 'Crude Condensate', 'Algerian Condensate', 'Agbami Condensate', \n",
    "            'Crude Condensate', 'Ichthys Condensate', 'High Sulphur Vacuum Gasoil']\n",
    "floating_storage_events_df = floating_storage_events_df[(floating_storage_events_df.cargo_group == 'Dirty') &\n",
    "                                                        (~floating_storage_events_df.cargo_type.isin(excluded))\n",
    "                                                       ].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floating_storage_events_df['floating_storage_end_date'] = floating_storage_events_df.apply(\n",
    "    lambda r: r['floating_storage_start_date'] + relativedelta(days=r['floating_storage_duration']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snake_to_camel(word):\n",
    "    return ''.join(x.capitalize() or '_' for x in word.split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floating_storage_events_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floating_storage_events_df.columns = [*map(snake_to_camel, floating_storage_events_df.columns)]\n",
    "floating_storage_events_df = floating_storage_events_df[['Imo', 'VoyageNumber', 'VesselClass', 'CargoType', 'Quantity',\n",
    "                                                         'PortName', 'Country', 'FloatingStorageStartDate',\n",
    "                                                         'FloatingStorageEndDate'\n",
    "                                                        ]].copy()\n",
    "floating_storage_events_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min and max dates for consideration\n",
    "date_min = date(2020, 2, 1)\n",
    "date_max = date(2020, 8, 1)\n",
    "\n",
    "delta = (date_max - date_min).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_on_water_data = []\n",
    "\n",
    "for iDay in range(delta):\n",
    "    curr_date = date_min + relativedelta(days=iDay)\n",
    "    quantity_on_water = floating_storage_events_df[(floating_storage_events_df.FloatingStorageStartDate <= curr_date) &\n",
    "                                                   (floating_storage_events_df.FloatingStorageEndDate >= curr_date)\n",
    "                                                  ].Quantity.sum()\n",
    "    oil_on_water_data.append([curr_date, quantity_on_water])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_on_water_series = pd.DataFrame(oil_on_water_data, columns=['Date', 'Quantity'])\n",
    "oil_on_water_series['Quantity'] = oil_on_water_series['Quantity'] / 10 ** 6 # million metric tonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_on_water_series.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize=(5, 3))\n",
    "axes1 = fig1.add_axes([0, 0, 1, 1])\n",
    "axes1.plot(oil_on_water_series.Date, oil_on_water_series.Quantity)\n",
    "axes1.set_title('Oil on water between February and August, 2020.')\n",
    "axes1.set_xlabel('Date')\n",
    "axes1.set_ylabel('Quantity (million MT)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chu_-neRSojI"
   },
   "outputs": [],
   "source": [
    "#voyages.to_excel('voyages_data.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of VoyagesAPI-VoyagesDataLike.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
